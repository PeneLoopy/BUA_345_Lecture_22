---
title: "BUA 345 - Lecture 22 - Intro to Forecasting"
author: "Penelope Pooler Eisenbies"
date: "`r Sys.Date()`"
output: 
  html_document: 
    code_folding: show
    toc: yes
    toc_depth: 4
    toc_float: yes
---

### Setup Chunk for Lecture 22

```{r setup for Lecture 22, include = T}

# this line specifies options for default options for all R Chunks
knitr::opts_chunk$set(echo=T, highlight=T)
# suppress scientific notation
options(scipen=100)

# install helper package that loads and installs other packages, if needed
if (!require("pacman")) install.packages("pacman", repos = "http://lib.stat.cmu.edu/R/CRAN/")

# install and load required packages
pacman::p_load(pacman,tidyverse, magrittr, knitr, gridExtra, forecast, tidyquant, lubridate, maps, usdata, mapproj, ggthemes, RColorBrewer, dygraphs)

# verify packages - it's a long list
p_loaded()

```

#### Cross-Sectional Data

- Shows a Snapshot of One Time Period

```{r golden snowball 2023}

gsb23 <- read_csv("gsb_23.csv", show_col_types = F, skip=25, 
                  col_select = c(1,2,6), ) |>
  slice(1:5) |>
  rename("city" = "...1", 
         "2022-23" = "...2", 
         "Most" = "...6") |> 
  
  mutate(Most = substr(Most, 1,5) |> as.numeric()) 

gsb_long <- gsb23 |> pivot_longer(cols = `2022-23`:Most, 
                               names_to = "type",
                               values_to = "inches") 
(gsb_plt <- gsb_long |>
  ggplot() +
  geom_bar(aes(x=city, y=inches, fill=type),
                stat="identity", position="dodge") +
  scale_fill_manual(values=c("blue4", "lightblue")) +
  theme_classic() +
  labs(fill="", x="City", y="Snowfall (inches)",
       caption="Data Source: https://goldensnowball.com/",
       title="City Snowfall - Current and All-time Record")+ 
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 10),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 8),
        axis.text.y = element_text(size = 15),
         plot.background = 
          element_rect(colour = "darkgrey", fill=NA, size=2)))


```

#### Time Series Data

- Shows Trend over Time

```{r snowfall time series}

snowfall <- read_csv("snowfall_upstateny_cities.csv", 
                     show_col_types = F) |>
  filter(!Season=="Season") |>
  separate(Season, into=c("Season_Start", "Season_End"), sep = "-") |>
  mutate(Season_Start = Season_Start |> as.integer(),
         Season_End = Season_Start + 1 |> as.integer(),
         Syracuse = Syracuse |> as.numeric(), 
         Buffalo = Buffalo |> as.numeric()) |>
  rename("city_most" = "City With Most Snow") |>
  select(Season_End, Syracuse, Buffalo, city_most) |>
  filter(Season_End >= 1952) |>
  pivot_longer(cols=Syracuse:Buffalo, names_to = "City", values_to = "Snowfall") 
   
(line_plot <- snowfall |>
  ggplot() +
  geom_line(aes(x=Season_End, y=Snowfall, color=City), linewidth=1) +
  theme_classic() + 
  scale_x_continuous(breaks=seq(1960, 2020, 10)) + 
  scale_color_manual(values=c("lightblue", "blue")) +
  ylim(0,200) +
  
  labs(title="Syracuse Annual Snowfall", 
       y="Snowfall (inches)", 
       x="Year Season Ended", 
       caption="Data Source: https://en.wikipedia.org/wiki/Golden_Snowball_Award") + 
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 10),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 15),
         plot.background = 
          element_rect(colour = "darkgrey", fill=NA, size=2)))

```

---

### U.S. Population - Cross-Sectional Data


```{r ln pop map}

us_counties <- map_data("county") |>                 # county polygons
  rename("state" = "region", "county" = "subregion")
# unique(us_counties$county[us_counties$state=="louisiana"])   # note issue Louisiana counties
cnty2019_all <- county_2019
# unique(cnty2019_all$name[cnty2019_all$state=="Louisiana"]) # note issue Louisiana counties

cnty2019_all <- cnty2019_all |> 
  mutate(state = tolower(state),
         county = tolower(name),
         county = gsub(" county", "", county),
         county = gsub(" parish", "", county),
         county = gsub("\\.", "", county))            # \\ is required because . used in R coding

cnty2019_all <- full_join(us_counties,cnty2019_all)   |>
  select(long:county, pop) |>
  mutate(pop1k = pop/1000)

# plot of logged data
# transformation and breaks statement added
(cnty_lpop <- cnty2019_all |>
  ggplot(aes(x=long, y=lat, group=group, fill=pop1k)) +
    geom_polygon() +
    theme_map() +
    coord_map("albers", lat0 = 39, lat1 = 45) +
    labs(fill= "", title="Population by County",
         subtitle="Unit is 1000 People and Date are Log-transformed",
         caption="Data Source: R usdata package") +
    scale_fill_continuous(type = "viridis",trans="log",
                          breaks=c(1,10,100,1000,10000)) +
    theme(legend.position = "bottom",
          legend.key.width = unit(1, "cm"),
          plot.title = element_text(size = 15),
          plot.subtitle = element_text(size = 10),
          plot.caption = element_text(size = 8),
         plot.background = element_rect(colour = "darkgrey", fill=NA, size=2)))

```

---

### U.S. Population - Time Series Data

- [U.S. Population 1950 - 2023](https://www.macrotrends.net/countries/USA/united-states/population)


```{r, pop trend}

uspop <- read_csv("pop_trend_1950_2023.csv", show_col_type = F) |>
  select(Time, Value) |>
  rename("Year" = "Time", "Population" = "Value") |>
  mutate(popM = Population/1000000)

 (pop_plt <- uspop |>
  ggplot() +
  geom_line(aes(x=Year, y=popM), color="blue", size=1) +
  theme_classic() + 
  scale_x_continuous(breaks=seq(1945, 2025, 10)) + 
  
  labs(title="U.S. Population - 1950 - 2023", y="Population (millions)", 
       caption="Data Source: https://www.macrotrends.net/countries/USA/united-states/population") + 
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 8),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size = 12),
         plot.background = element_rect(colour = "darkgrey", fill=NA, size=2)))

```

---


### U.S. Population - Interactive Plot

```{r pop dygraph}

# convert to xts (extensible time series)
uspop <- uspop |>
  mutate(date=ym(paste(Year,12)))
uspop_xts <- xts(x=uspop[,3], order.by= uspop$date)

# create interactive plot
dygraph(uspop_xts, main="US Population 1950 - 2023") |>
  dySeries("popM", label="Pop. (Mill.)", color= "darkmagenta") |>
  dyAxis("y", label = "", drawGrid = FALSE) |>
  dyAxis("x", label = "", drawGrid = FALSE) |>
  dyShading(from="2020-3-12", to="2021-6-14", color = "lightgrey") |>
  dyRangeSelector()


```



### U.S. Population - Modeling Time Series Data


#### Population Trend Forecast

- Create time series using population data

  - Specify `freq = 1` - one observation per year

  - Specify `start = 1950` - first year in dataset
    

- Model data using `auto.arima` function

  - Specify `ic = aic` - `aic` is the information criterion used to determine model.

  - Specify `seasonality = F` - no seasonal (repeating) pattern in the data.
    

- This chunk will create and save the model.


```{r create pop time series and model}

# create time series for forecast
pop_ts <- ts(uspop$popM, freq=1, start=1950)

# model data using auto.arima function
pop_model <- auto.arima(pop_ts, ic="aic", seasonal=F)

```

---

### U.S. Population - Create and Plot Forecasts


**Create forecasts (until 2040)**

- `h = 17` indicates we want to forecast 17 years
    
- Most recent year in data is 2023
   
   - 2040 - 2022 - 17
   
- **Forecasts become less accurate the further into the future you specify.**

```{r create forecasts}

# create forecasts (until 2040)
pop_forecast <- forecast(pop_model, h=17)

```

---

### U.S. Population - Create and Plot Forecasts

- Darker purple: 80% Prediction Interval Bounds
- Lighter purple: 95% Prediction Interval Bounds
- Plot shows:
  - Lags (`p = 5`), Differencing (`d = 1`), Moving Average (`q = 1`)

```{r plot pop forecasts with pred intervals, fig.dim=c(7,4)}

autoplot(pop_forecast) + 
  labs(y = "U.S. Population (Millions)") +
  theme_classic()

```

---

### U.S. Population - Examine Numerical Forecasts

- Point Forecast is the forecasted estimate for each future time period
- Lo 80 and Hi 80 are the lower and upper bounds for the 80% prediction interval
- Lo 95 and Hi 95 are the lower and upper bounds for the 95% prediction interval

```{r numerical forecasts}
# print out forecasts
pop_forecast
```



### U.S. Population - Examine Residuals and Model Fit


```{r pop residual plots}
# examine residuals
checkresiduals(pop_forecast)

```

#### Examining Residuals:

- Top Plot: No spikes should be too large
  
  - One obs. seems large and should be checked.

- ACF: auto-correlation function.
  
  - Ideally, all or most values are with dashed lines
    

- Histogram: Distribution of residuals should be approx. normal
  
  - We have one high outlier
    
  - Assessment: Trend is very smooth so small aberrations are exaggerated in residuals.
]

---

### U.S. Population - Examine Residuals and Model Fit

```{r pop fit statistics }

# examine model accuracy (fit)
(acr <- accuracy(pop_forecast))

```

#### Fit Statistics for Model Comparisons

- Many options for comparing models

- **For BUA 345:** We will use MAPE = Mean Absolute Percent Error

  - **(100 – MAPE) = Percent accuracy of model.**

- Despite outlier and one large ACF value, our population model is estimated to be  `r round(100 - acr[5],2)`% accurate.

- This doesn’t guarantee that forecasts will be  `r round(100 - acr[5])`% accurate but it does improve our chances of accurate forecasting.

---

### Example 2: Netflix Stock Prices - Data from [Yahoo Finance](https://finance.yahoo.com/)

```{r import and plot Netflix data}

# import from yahoo finance and plot dygraph
getSymbols("NFLX", from = "2010-01-01", to = "2023-04-17")

# create interactive plot
(nflx_dg <- dygraph(NFLX[,c(2,3,6)], main="Netflix Stock price") |>
  dySeries("NFLX.Adjusted", label="Adj. Close", color= "purple") |>
  dySeries("NFLX.Low", label="Low", color= "blue") |>
  dySeries("NFLX.High", label="High", color= "red") |>
  dyAxis("y", label = "", drawGrid = FALSE) |>
  dyAxis("x", label = "", drawGrid = FALSE) |>
  dyShading(from="2020-3-12", to="2021-6-14", color = "lightgrey") |>
  dyRangeSelector())

```


---

### Netflix Stock

- Was mostly trending upward, but had a downturn and then another recent upturn.
- Data imported are daily adjusted close 
- Data we will use are monthly adjusted close (1st day of trading for each month)

```{r nflx monthly plot}

# convert xts to tibble
nflx <- NFLX |>
  fortify.zoo() |> as_tibble(.name_repair = "minimal") |>
  rename("Date" = "Index", "Adjusted" = "NFLX.Adjusted") |>
  mutate(year=year(Date), month=month(Date), day=day(Date)) |>
  group_by(year, month) |>
  filter(day == min(day, na.rm=T)) |>
  ungroup() |>
  select(Date, Adjusted)

(nflx_plot <- nflx |>
  ggplot() +
    
  geom_line(aes(x=Date, y=Adjusted), color="red", size=1) +
    
  theme_classic() +
    
  labs(title="Netflix Monthly Adjusted Closing Price",
       x="Date", Y="Adjusted Closing Price",
       caption = "Data Source:https://finance.yahoo.com/") +
  
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 8),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
         plot.background = element_rect(colour = "darkgrey", fill=NA, size=2)))



```


---

### Netflix Stock

- **Forecast Questions:** 

  - What will be the estimated stock price be in April of 2024?

  - What ARIMA model was chosen (p,d,q)?
  
--

- **Model Assessment Questions:**
     
  - How valid is our model? 
  
     - Check residual plots.
     
  - How are accurate are our estimates?

     - Examine Prediction Intervals and Prediction Bands
    
     - Check fit statistics


---

### Netflix Stock - Modeling Time Series Data 

#### Stock Trend Forecast

- Creat time series using Netflix Stock data

  - Specify `freq = 12` - 12 observations per year

  - Specify `start = c(2010, 1)` - first obs. in dataset is January 2010
    

- Model data using `auto.arima` function

  - Specify `ic = aic` - `aic` is the information criterion used to determine model.

  - Specify `seasonality = F` - no seasonal (repeating) pattern in the data.
    
--

-  This chunk will create and save the model.

```{r create nflx time series and model}

# create time series for forecast
nflx_ts <- ts(nflx$Adjusted, freq=12, start=c(2010,1))

# model data using auto.arima function
nflx_model <- auto.arima(nflx_ts, ic="aic", seasonal=F)

```

---

### Netflix Stock - Create and Plot Forecasts ![](Netflix.png)


-  Create forecasts (until April 2024)

   - `h = 12` indicates we want to forecast 12 months
    
   - Most recent month in data is April 2023
   
     - 12 Months until March 2023
   

- **Forecasts become less accurate the further into the future you specify.**


```{r create nflx forecasts}

# create forecasts (until April 2023)
nflx_forecast <- forecast(nflx_model, h=12)

```

---

### Netflix Stock - Create and Plot Forecasts ![](Netflix.png)

- Darker purple: 80% Prediction Interval Bounds
- Lighter purple: 95% Prediction Interval Bounds
- Plot shows:
  - Lags (`p = 2`), Differencing (`d = 1`), Moving Average (`q = 2`)

```{r plot nflx forecasts with pred intervals}

autoplot(nflx_forecast) + 
  labs(y = "Adjusted Closing Price") +
  theme_classic()

```

---

### Netflix Stock - Examine Numerical Forecasts ![](Netflix.png)

- Point Forecast is the forecasted estimate for each future time period

- Lo 80 and Hi 80 are the lower and upper bounds for the 80% prediction interval

- Lo 95 and Hi 95 are the lower and upper bounds for the 95% prediction interval

```{r nflx numerical forecasts}
# print out forecasts
nflx_forecast
```

---

### Lecture 18 In-class Exercises - Session ID: bua345s23**

#### **Question 3 (L22) - Interpretation of netflix Prediction Intervals
  
<br>

In January of 2024, the Netflix stock price is forecasted to be approximately $350  However the 95% prediction interval indicates it may be as low as `____`.

**How to input your answer:**

- Round to closest whole dollar.

- Don't include dollar sign.


---

### Netflix Stock - Examine Residuals and Model Fit

.pull-left[

```{r nflx residual plots}
# examine residuals
checkresiduals(nflx_forecast)

```
]

.pull-right[

#### Examining Residuals:

  - Top Plot: Spikes get larger over time 
  
  - ACF: auto-correlation function.
  
    - Ideally, all or most values are with dashed lines
    
  - Histogram: Distribution of residuals should be approx. normal
  
    - Appears okay
    
  - Assessment: Stock prices are very volatile and this is sufficient.
]

---


### Netflix Stock - Examine Residuals and Model Fit

```{r nflx fit statistics }    
 
# examine model accuracy (fit)
(acr <- accuracy(nflx_forecast))
    
```

--


#### Fit Statistics for Model Comparisons

- Many options for comparing models

- **For BUA 345:** We will use MAPE = Mean Absolute Percent Error

  - **100 – MAPE = Percent accuracy of model.**

- Despite increasing volatility, our stock price model is estimated to be `r round(100 - acr[5],2)`% accurate.

- This doesn’t guarantee that forecasts will be `r round(100 - acr[5])`% accurate but it does improve our chances of accurate forecasting.

---

### Key Points from Today



- **`forecast`** package in R simplifies forecasting**
 
- **Extrapolation OK in this case**

  - Report uncertainty as prediction bounds
  
- **You should know terminology and how to read and interpret output.**

  - You will be given data, R code, and output 

  - You will answer questions based on provided output.
  
- **HW 10 will cover Lectures 21-23**

  - Due Monday, 4/24/2022
   

You may submit an 'Engagement Question' about each lecture until midnight on the day of the lecture. **A minimum of four submissions are required during the semester.**






 
