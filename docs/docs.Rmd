---
title: "BUA 345 - Lecture 22"
subtitle: "Introduction to Forecasting"  
author: "Penelope Pooler Eisenbies"
date: '`r Sys.Date()`'
output:
  xaringan::moon_reader:
    seal: false
    css: xaringan-themer.css
    nature:
      slideNumberFormat: "%current%/%total%" 
      highlightStyle: tomorrow-night-bright
      highlightLines: true
      ratio: 16:9
      countIncrementalSlides: true
      keep_md: true
---

```{r setup, include=FALSE, echo=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  fig.retina=2,
  #out.width = "75%",
  #out.height = "50%",
  htmltools.preserve.raw = FALSE,      # needed for windows
  scipen=100,                          # suppresses scientific notation
  getSymbols.warning4.0 = FALSE,       # suppresses getSymbols warnings
  cache = FALSE,
  echo = TRUE,
  hiline = TRUE,
  message = FALSE, 
  warning = FALSE
)


# install helper package (pacman)
# pacman loads and installs other packages, if needed
if (!require("pacman")) install.packages("pacman", repos = "http://lib.stat.cmu.edu/R/CRAN/")

# install and load required packages
# pacman should be first package in parentheses and then list others
pacman::p_load(pacman,tidyverse, magrittr, knitr, gridExtra, forecast, tidyquant, lubridate, maps, usdata, mapproj, ggthemes, RColorBrewer, dygraphs)

# verify packages (comment out in finished documents)
p_loaded()


```

```{r xaringan-themer, include=FALSE, warning=FALSE}
library(xaringanthemer)

palette <- c(
  SU_Orange1        = "#F76900",
  SU_Orange2        = "#FF8E00",
  SU_Red_Orange     = "#FF431B",
  SU_Blue1          = "#000E54",
  SU_Blue2          = "#203299",
  SU_Light_Blue     = "#2B72D7",
  SU_White          = "#FFFFFF",
  SU_Light_Gray     = "#ADB3B8",
  SU_Medium_Gray    = "#707780",
  SU_Black          = "#000000", 
  
  steel_blue        = "#4682B4",
  corn_flower_blue  = "#6495ED",
  deep_sky_blue     = "#00BFFF",
  dark_magenta      = "#8B008B",
  medium_orchid     = "#BA55D3",
  lime_green        = "#32CD32",
  light_sea_green   = "#20B2AA",
  chartreuse        = "#7FFF00",
  orange_red        = "#FF4500",
  white_smoke       = "#F5F5F5",
  dark_cyan         = "#008B8B",
  light_steel_blue  = "#B0C4DE",
  indigo            = "#4B0082",
  ivory             = "#FFFFF0",
  light_slate_grey  = "#778899",
  linen             = "#FAF0E6",
  steel_blue        = "#4682B4",
  blue_violet       = "#8A2BE2",
  dodger_blue       = "#1E90FF",
  light_blue        = "#ADD8E6",
  azure             = "#F0FFFF",
  lavender          = "#E6E6FA")

primary_color = "#4682B4"                # steel_blue
secondary_color = "#778899"              # light_slate_grey
white_color = "#FFFFF0"                  # ivory
black_color = "#000080"                  # navy

style_duo_accent(
  primary_color = primary_color,
  secondary_color = secondary_color,
  white_color = white_color,
  black_color = black_color,
  text_color = black_color,
  header_color = primary_color,
  background_color = white_color,
  code_inline_background_color = "#E6E6FA", # lavender
  link_color = "#1E90FF",                   # dodger_blue
  code_inline_color = "#4B0082",            # indigo
  text_bold_color = "#8B008B",              # dark_magenta
  header_font_google = google_font("Open Sans"),
  text_font_google = google_font("Open Sans"),
  code_font_google = google_font("Source Code Pro"),
  colors = palette
)


```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r xaringan-tile-view, echo=FALSE}
xaringanExtra::use_tile_view()
```

```{r xaringan-fit-screen, echo=FALSE}
xaringanExtra::use_fit_screen()
```

```{r xaringan-tachyons, echo=FALSE}
xaringanExtra::use_tachyons()
```

```{r xaringan-animate-css, echo=FALSE}
xaringanExtra::use_animate_css()
```

```{r xaringan-animate-all, echo=FALSE}
#xaringanExtra::use_animate_all("slide_up")
```

background-image: url("docs_files/images/sloth_faded.png")
background-size: cover

class: bottom, right

## BUA 345 - Lecture 22

### Introduction to Forecasting

<br>


#### Penelope Pooler Eisenbies

#### `r Sys.Date()`

[Wikipedia Sloth Page](https://en.wikipedia.org/wiki/Sloth)

---

### Upcoming Dates

.pull-left[

- **HW 9 was due on Monday, 4/17**. 

   - Grace Period ends tonight (Tues. 4/18) at midnight.
   
- **HW 10 is due Monday, 4/24**

- **Course Review on 4/27** 

]

.pull-right[

```{r owl pic, echo=FALSE}

knitr::include_graphics("docs_files/images/owl.png")

```

]

---

### Reminder of Using R and R Markdown Files

.pull-left[

- Download Zipped R project 

- Open Zipped folder and copy internal folder (R Project) to a BUA 345 folder on your computer NOT IN DOWLOADS

- **Open R Project:**
  
  - *OPTION 1:* Click on .Rproj file to open project and RStudio

  - *OPTION 2:* Open RStudio, then click File > Open Project > then navigate to  and click on .Rproj file.
  

- **Once Project is opened in RStudio:**

  - Click on `code_data_output` file to open it.

  - Click on `BUA_345_Lecture_22.Rmd` to open it.

  - Run `setup` Chunk


]

.pull-right[

```{r beaver pic, echo=FALSE}

knitr::include_graphics("docs_files/images/beaver.png")

```

]

---

### Setup

.pull-left[

- The setup chunk shows the packages needed for this demo.   

- R will install specified packages if needed (only required once after R is installed)  

- R will load specified packaged (required every time you start a new R session)  

- The first time you run this code, R will install these packages which will be slow.  

- **If you get warnings, that's okay.**  

- If you get **error messages**, I (or TA), can help you.

]


.pull-right[

```{r owl pic2, echo=FALSE}

knitr::include_graphics("docs_files/images/owl.png")

```

]


---

### Setup Chunk for Lecture 18

```{r setup for Lecture 18, include = T}

# this line specifies options for default options for all R Chunks
knitr::opts_chunk$set(echo=T, highlight=T)
# suppress scientific notation
options(scipen=100)

# install helper package that loads and installs other packages, if needed
if (!require("pacman")) install.packages("pacman", repos = "http://lib.stat.cmu.edu/R/CRAN/")

# install and load required packages
pacman::p_load(pacman,tidyverse, magrittr, knitr, gridExtra, forecast, tidyquant, lubridate, maps, usdata, mapproj, ggthemes, RColorBrewer, dygraphs)

# verify packages - it's a long list
#p_loaded()

```

**NOTES:**

- Please make sure you can open the provided R project for the practice questions and run the setup chunk without errors.
- If you are having trouble installing/loading any packages, please come to office hour or make an appointment with me or course TA.

---

### Lecture 18 In-class Exercises - Session ID: bua345s23**

#### **Question 1 (L22) - Review from Regression concepts
  
We have data for 2022 annual salaries of 75 Upstate NY residents ranging from `$50K` to `$150K`.
and we use that data to model how much someone spends on their first house.

**Is it valid to apply that model to someone with an annual salary of `$350K`?**

<br>

A. Yes, this is extrapolation and it is valid

B. No this is extrapolation and it is invalid

C. Yes, this is interpolation and it is valid

D No this is interpolation and it is invalid


---

### Introduction to Forecasting

#### Today's Topics

- **Cross-Sectional Data vs. Time Series Data**

- Basic Forecasting Terminology

- Forecasting Trends without Seasonality in R

  - Example 1 - US Population
  
  - Example 2 - Netflix Stock Prices
  
#### HW Assignment 10

- **Today:** Questions 2 - 6 
  
---

.pull-left[

#### Cross-Sectional Data

- Shows a Snapshot of One Time Period

```{r echo = F, message = FALSE, fig.align='center'}

gsb23 <- read_csv("gsb_23.csv", show_col_types = F, skip=25, 
                  col_select = c(1,2,6), ) |>
  slice(1:5) |>
  rename("city" = "...1", 
         "2022-23" = "...2", 
         "Most" = "...6") |> 
  
  mutate(Most = substr(Most, 1,5) |> as.numeric()) 

gsb_long <- gsb23 |> pivot_longer(cols = `2022-23`:Most, 
                               names_to = "type",
                               values_to = "inches") 
(gsb_plt <- gsb_long |>
  ggplot() +
  geom_bar(aes(x=city, y=inches, fill=type),
                stat="identity", position="dodge") +
  scale_fill_manual(values=c("blue4", "lightblue")) +
  theme_classic() +
  labs(fill="", x="City", y="Snowfall (inches)",
       caption="Data Source: https://goldensnowball.com/",
       title="City Snowfall - Current and All-time Record")+ 
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 10),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 8),
        axis.text.y = element_text(size = 15),
         plot.background = 
          element_rect(colour = "darkgrey", fill=NA, size=2)))


```

]

.pull-right[

#### Time Series Data

- Shows Trend over Time

```{r syr snowfall timeseries, echo=F, message=F, fig.align='center'}

snowfall <- read_csv("snowfall_upstateny_cities.csv", 
                     show_col_types = F) |>
  filter(!Season=="Season") |>
  separate(Season, into=c("Season_Start", "Season_End"), sep = "-") |>
  mutate(Season_Start = Season_Start |> as.integer(),
         Season_End = Season_Start + 1 |> as.integer(),
         Syracuse = Syracuse |> as.numeric(), 
         Buffalo = Buffalo |> as.numeric()) |>
  rename("city_most" = "City With Most Snow") |>
  select(Season_End, Syracuse, Buffalo, city_most) |>
  filter(Season_End >= 1952) |>
  pivot_longer(cols=Syracuse:Buffalo, names_to = "City", values_to = "Snowfall") 
   
(line_plot <- snowfall |>
  ggplot() +
  geom_line(aes(x=Season_End, y=Snowfall, color=City), linewidth=1) +
  theme_classic() + 
  scale_x_continuous(breaks=seq(1960, 2020, 10)) + 
  scale_color_manual(values=c("lightblue", "blue")) +
  ylim(0,200) +
  
  labs(title="Syracuse Annual Snowfall", 
       y="Snowfall (inches)", 
       x="Year Season Ended", 
       caption="Data Source: https://en.wikipedia.org/wiki/Golden_Snowball_Award") + 
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 10),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 15),
         plot.background = 
          element_rect(colour = "darkgrey", fill=NA, size=2)))

```

]

---

### U.S. Population - Cross-Sectional Data


```{r echo=F, message=F, fig.align='center', fig.dim=c(15,7)}

us_counties <- map_data("county") |>                 # county polygons
  rename("state" = "region", "county" = "subregion")
# unique(us_counties$county[us_counties$state=="louisiana"])   # note issue Louisiana counties
cnty2019_all <- county_2019
# unique(cnty2019_all$name[cnty2019_all$state=="Louisiana"]) # note issue Louisiana counties

cnty2019_all <- cnty2019_all |> 
  mutate(state = tolower(state),
         county = tolower(name),
         county = gsub(" county", "", county),
         county = gsub(" parish", "", county),
         county = gsub("\\.", "", county))            # \\ is required because . used in R coding

cnty2019_all <- full_join(us_counties,cnty2019_all)   |>
  select(long:county, pop) |>
  mutate(pop1k = pop/1000)

# plot of logged data
# transformation and breaks statement added
(cnty_lpop <- cnty2019_all |>
  ggplot(aes(x=long, y=lat, group=group, fill=pop1k)) +
    geom_polygon() +
    theme_map() +
    coord_map("albers", lat0 = 39, lat1 = 45) +
    labs(fill= "", title="Population by County",
         subtitle="Unit is 1000 People and Date are Log-transformed",
         caption="Data Source: R usdata package") +
    scale_fill_continuous(type = "viridis",trans="log",
                          breaks=c(1,10,100,1000,10000)) +
    theme(legend.position = "bottom",
          legend.key.width = unit(1, "cm"),
          plot.title = element_text(size = 15),
          plot.subtitle = element_text(size = 10),
          plot.caption = element_text(size = 8),
         plot.background = element_rect(colour = "darkgrey", fill=NA, size=2)))

```


---

### U.S. Population - Time Series Data

- [U.S. Population 1950 - 2023](https://www.macrotrends.net/countries/USA/united-states/population)


```{r, echo=F, message=F, fig.align='center', fig.dim=c(15,7)}

uspop <- read_csv("pop_trend_1950_2023.csv", show_col_type = F) |>
  select(Time, Value) |>
  rename("Year" = "Time", "Population" = "Value") |>
  mutate(popM = Population/1000000)

 (pop_plt <- uspop |>
  ggplot() +
  geom_line(aes(x=Year, y=popM), color="blue", size=1) +
  theme_classic() + 
  scale_x_continuous(breaks=seq(1945, 2025, 10)) + 
  
  labs(title="U.S. Population - 1950 - 2023", y="Population (millions)", 
       caption="Data Source: https://www.macrotrends.net/countries/USA/united-states/population") + 
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 8),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 12),
        axis.text.y = element_text(size = 12),
         plot.background = element_rect(colour = "darkgrey", fill=NA, size=2)))

```

---

### Time Series Terminology

In time series data, new observations are often correlated with prior observations

- This is referred to as **auto-correlation**

  - A variable is correlated with itself
  
  - When data are auto-correlated, we use that information
  
  - This process is called **auto-regression**
  
    - Using previous observations to predict into the future.
  
- **R function:** **`auto.arima`** function in **`forecast`** package

  - **ARIMA** is an acronym:

     - **AR:** auto-regressive
  
     - **I:** integrated
  
     - **MA:** moving average
  
- In **ARIMA** models, all three components are optimized to provide a reliable forecast.
  
---

### Terminology: ARIMA model components (p, d, q)

#### Auto-Regressive Models (AR)

- Similar to a simple linear regression model or non-linear regression model

- Key difference: Regressor or predictor variable is dependent variable with a specific LAG

- Lag (**p**) is how many previous time periods the model looks back to estimate the next time period.

  - If **p = 1**, the model estimates the next time period based on most recent one. 
   
     - Looks back **one** time period
     
  - If **p = 2**, the model estimates the next time period on time period **BEFORE** the most recent one.
  
     - Looks back **two** time periods
     
---

### Example 1: U.S. Population - 1950 to Present 
.pull-right[

```{r echo=F, message=F, fig.dim=c(5,4)}

(pop_plt <- uspop |>
  ggplot() +
  geom_line(aes(x=Year, y=popM), color="blue", size=1) +
  theme_classic() + 
  scale_x_continuous(breaks=seq(1945, 2025, 10)) + 
  labs(title="U.S. Population - 1950 - 2023", y="Population (millions)") + 
  theme(plot.background = element_rect(colour = "darkgrey", fill=NA, size=2)))

```

]

.pull-left[

]

- **Forecast Questions:** 

  - What will the U.S. Population be in 2040?

  - What ARIMA model was chosen (p,d,q)?
  
<br>

- **Model Assessment Questions:**

  - How valid is our model? 
  
     - Check residual plots.
  
  - How accurate are our estimates?

     - Examine Prediction Intervals and Prediction Bands
    
     - Check fit statistics


---

### Terminology: ARIMA model components (p, d, q)

#### Differencing (I = Integration) 

- **Stationarity:** mean and variance of data are consistent over timespan

  - needed for accurate modeling

  - Can be verified by examining residuals
  
- **Differencing** transforms non-stationary data to stationary

- Differencing order (**d**) determined by model:
  
  - if **d = 1:** each obs. is difference from previous one (linear)
  
  - if **d = 2:** each obs. is difference of difference from previous one (quadratic)
  

---

### Terminology: ARIMA model components (p, d, q) .pull-right[![](covid_ma.png)]

#### Moving Average (MA)

- Moving average (**q**): how many terms are incorporated into each average within the data. 

- Algorithm calculates the average for a specific number of lagged terms

- Moving Averages smooths out temporary instability in the data 

  - If **q = 1:** moving average is average of current term with the one from the previous time period.

  - If **q = 2:**, moving average is average of the current term with the ones from two previous time periods.
  
---


### U.S. Population - Interactive Plot

```{r dygraph, echo=F, fig.dim=c(15,7)}

# convert to xts (extensible time series)
uspop <- uspop |>
  mutate(date=ym(paste(Year,12)))
uspop_xts <- xts(x=uspop[,3], order.by= uspop$date)

# create interactive plot
dygraph(uspop_xts, main="US Population 1950 - 2023") |>
  dySeries("popM", label="Pop. (Mill.)", color= "darkmagenta") |>
  dyAxis("y", label = "", drawGrid = FALSE) |>
  dyAxis("x", label = "", drawGrid = FALSE) |>
  dyShading(from="2020-3-12", to="2021-6-14", color = "lightgrey") |>
  dyRangeSelector()


```

---

### U.S. Population - Modeling Time Series Data


#### Population Trend Forecast

- Create time series using population data

  - Specify `freq = 1` - one observation per year

  - Specify `start = 1950` - first year in dataset
    

- Model data using `auto.arima` function

  - Specify `ic = aic` - `aic` is the information criterion used to determine model.

  - Specify `seasonality = F` - no seasonal (repeating) pattern in the data.
    

- This chunk will create and save the model.


```{r create pop time series and model}

# create time series for forecast
pop_ts <- ts(uspop$popM, freq=1, start=1950)

# model data using auto.arima function
pop_model <- auto.arima(pop_ts, ic="aic", seasonal=F)

```

---

### U.S. Population - Create and Plot Forecasts


**Create forecasts (until 2040)**

- `h = 17` indicates we want to forecast 17 years
    
- Most recent year in data is 2023
   
   - 2040 - 2022 - 17
   
- **Forecasts become less accurate the further into the future you specify.**

```{r create forecasts}

# create forecasts (until 2040)
pop_forecast <- forecast(pop_model, h=17)

```

---

### U.S. Population - Create and Plot Forecasts

- Darker purple: 80% Prediction Interval Bounds
- Lighter purple: 95% Prediction Interval Bounds
- Plot shows:
  - Lags (`p = 5`), Differencing (`d = 1`), Moving Average (`q = 1`)

```{r plot pop forecasts with pred intervals, fig.dim=c(7,4)}

autoplot(pop_forecast) + 
  labs(y = "U.S. Population (Millions)") +
  theme_classic()

```

---

### U.S. Population - Examine Numerical Forecasts

- Point Forecast is the forecasted estimate for each future time period
- Lo 80 and Hi 80 are the lower and upper bounds for the 80% prediction interval
- Lo 95 and Hi 95 are the lower and upper bounds for the 95% prediction interval

```{r numerical forecasts}
# print out forecasts
pop_forecast
```

---

### Lecture 18 In-class Exercises - Session ID: bua345s23**

#### **Question 2 (L22) - Interpretation of Pop. Prediction Intervals

<br>
  
Based on the US Population forecast output, we are 95% certain that U.S population in 2030 will be less than `______` million people? 

**How to input your answer:**

- Round to closest million (whole number)

- If the answer were 123 million (e.g. 123.4233), you would enter 123. 

---

### U.S. Population - Examine Residuals and Model Fit

.pull-left[

```{r pop residual plots, fig.dim=c(5,6)}
# examine residuals
checkresiduals(pop_forecast)

```

]

.pull-right[

#### Examining Residuals:

- Top Plot: No spikes should be too large
  
  - One obs. seems large and should be checked.

- ACF: auto-correlation function.
  
  - Ideally, all or most values are with dashed lines
    

- Histogram: Distribution of residuals should be approx. normal
  
  - We have one high outlier
    
  - Assessment: Trend is very smooth so small aberrations are exaggerated in residuals.
]

---

### U.S. Population - Examine Residuals and Model Fit

```{r pop fit statistics }

# examine model accuracy (fit)
(acr <- accuracy(pop_forecast))

```
#### Fit Statistics for Model Comparisons

- Many options for comparing models

- **For BUA 345:** We will use MAPE = Mean Absolute Percent Error

  - **(100 – MAPE) = Percent accuracy of model.**

- Despite outlier and one large ACF value, our population model is estimated to be  `r round(100 - acr[5],2)`% accurate.

- This doesn’t guarantee that forecasts will be  `r round(100 - acr[5])`% accurate but it does improve our chances of accurate forecasting.

---

### Example 2: Netflix Stock Prices - Data from [Yahoo Finance](https://finance.yahoo.com/)

```{r import Netflix data, results='hide', echo=F}

# import from yahoo finance and plot dygraph
getSymbols("NFLX", from = "2010-01-01", to = "2023-04-17")

```

```{r echo=F, fig.align='center', fig.dim=c(15,7)}

# create interactive plot
(nflx_dg <- dygraph(NFLX[,c(2,3,6)], main="Netflix Stock price") |>
  dySeries("NFLX.Adjusted", label="Adj. Close", color= "purple") |>
  dySeries("NFLX.Low", label="Low", color= "blue") |>
  dySeries("NFLX.High", label="High", color= "red") |>
  dyAxis("y", label = "", drawGrid = FALSE) |>
  dyAxis("x", label = "", drawGrid = FALSE) |>
  dyShading(from="2020-3-12", to="2021-6-14", color = "lightgrey") |>
  dyRangeSelector())

```


---

### Netflix Stock

- Was mostly trending upward, but had a downturn and then another recent upturn.
- Data imported are daily adjusted close 
- Data we will use are monthly adjusted close (1st day of trading for each month)

```{r echo=F, message=F, fig.align='center', fig.dim=c(14,6)}

# convert xts to tibble
nflx <- NFLX |>
  fortify.zoo() |> as_tibble(.name_repair = "minimal") |>
  rename("Date" = "Index", "Adjusted" = "NFLX.Adjusted") |>
  mutate(year=year(Date), month=month(Date), day=day(Date)) |>
  group_by(year, month) |>
  filter(day == min(day, na.rm=T)) |>
  ungroup() |>
  select(Date, Adjusted)

(nflx_plot <- nflx |>
  ggplot() +
    
  geom_line(aes(x=Date, y=Adjusted), color="red", size=1) +
    
  theme_classic() +
    
  labs(title="Netflix Monthly Adjusted Closing Price",
       x="Date", Y="Adjusted Closing Price",
       caption = "Data Source:https://finance.yahoo.com/") +
  
  theme(plot.title = element_text(size = 15),
        plot.caption = element_text(size = 8),
        axis.title.x = element_text(size = 15),
        axis.title.y = element_text(size = 15),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
         plot.background = element_rect(colour = "darkgrey", fill=NA, size=2)))



```


---

### Netflix Stock

- **Forecast Questions:** 

  - What will be the estimated stock price be in April of 2024?

  - What ARIMA model was chosen (p,d,q)?
  
--

- **Model Assessment Questions:**
     
  - How valid is our model? 
  
     - Check residual plots.
     
  - How are accurate are our estimates?

     - Examine Prediction Intervals and Prediction Bands
    
     - Check fit statistics


---

### Netflix Stock - Modeling Time Series Data 

#### Stock Trend Forecast

- Creat time series using Netflix Stock data

  - Specify `freq = 12` - 12 observations per year

  - Specify `start = c(2010, 1)` - first obs. in dataset is January 2010
    

- Model data using `auto.arima` function

  - Specify `ic = aic` - `aic` is the information criterion used to determine model.

  - Specify `seasonality = F` - no seasonal (repeating) pattern in the data.
    
--

-  This chunk will create and save the model.

```{r create nflx time series and model}

# create time series for forecast
nflx_ts <- ts(nflx$Adjusted, freq=12, start=c(2010,1))

# model data using auto.arima function
nflx_model <- auto.arima(nflx_ts, ic="aic", seasonal=F)

```

---

### Netflix Stock - Create and Plot Forecasts ![](Netflix.png)


-  Create forecasts (until April 2024)

   - `h = 12` indicates we want to forecast 12 months
    
   - Most recent month in data is April 2023
   
     - 12 Months until March 2023
   

- **Forecasts become less accurate the further into the future you specify.**


```{r create nflx forecasts}

# create forecasts (until April 2023)
nflx_forecast <- forecast(nflx_model, h=12)

```

---

### Netflix Stock - Create and Plot Forecasts ![](Netflix.png)

- Darker purple: 80% Prediction Interval Bounds
- Lighter purple: 95% Prediction Interval Bounds
- Plot shows:
  - Lags (`p = 2`), Differencing (`d = 1`), Moving Average (`q = 2`)

```{r plot nflx forecasts with pred intervals, fig.dim=c(7,4)}

autoplot(nflx_forecast) + 
  labs(y = "Adjusted Closing Price") +
  theme_classic()

```

---

### Netflix Stock - Examine Numerical Forecasts ![](Netflix.png)

- Point Forecast is the forecasted estimate for each future time period

- Lo 80 and Hi 80 are the lower and upper bounds for the 80% prediction interval

- Lo 95 and Hi 95 are the lower and upper bounds for the 95% prediction interval

```{r nflx numerical forecasts}
# print out forecasts
nflx_forecast
```

---

### Lecture 18 In-class Exercises - Session ID: bua345s23**

#### **Question 3 (L22) - Interpretation of netflix Prediction Intervals
  
<br>

In January of 2024, the Netflix stock price is forecasted to be approximately $350  However the 95% prediction interval indicates it may be as low as `____`.

**How to input your answer:**

- Round to closest whole dollar.

- Don't include dollar sign.


---

### Netflix Stock - Examine Residuals and Model Fit

.pull-left[

```{r nflx residual plots, fig.dim=c(5,6)}
# examine residuals
checkresiduals(nflx_forecast)

```
]

.pull-right[

#### Examining Residuals:

  - Top Plot: Spikes get larger over time 
  
  - ACF: auto-correlation function.
  
    - Ideally, all or most values are with dashed lines
    
  - Histogram: Distribution of residuals should be approx. normal
  
    - Appears okay
    
  - Assessment: Stock prices are very volatile and this is sufficient.
]

---


### Netflix Stock - Examine Residuals and Model Fit

```{r nflx fit statistics }    
 
# examine model accuracy (fit)
(acr <- accuracy(nflx_forecast))
    
```

--


#### Fit Statistics for Model Comparisons

- Many options for comparing models

- **For BUA 345:** We will use MAPE = Mean Absolute Percent Error

  - **100 – MAPE = Percent accuracy of model.**

- Despite increasing volatility, our stock price model is estimated to be `r round(100 - acr[5],2)`% accurate.

- This doesn’t guarantee that forecasts will be `r round(100 - acr[5])`% accurate but it does improve our chances of accurate forecasting.

---

background-image: url("docs_files/images/tired_panda_faded.png")
background-size: cover

.pull-left[

### Key Points from Today

.bg-azure.b--dark_cyan.ba.bw2.br3.shadow-5.ph2[

- **`forecast`** package in R simplifies forecasting**
 
- **Extrapolation OK in this case**

  - Report uncertainty as prediction bounds
  
- **You should know terminology and how to read and interpret output.**

  - You will be given data, R code, and output 

  - You will answer questions based on provided output.
  
- **HW 10 will cover Lectures 21-23**

  - Due Monday, 4/24/2022
   

]

]

.pull-right[

.bg-azure.b--dark_cyan.ba.bw2.br3.shadow-5.ph3[
You may submit an 'Engagement Question' about each lecture until midnight on the day of the lecture. **A minimum of four submissions are required during the semester.**
]

]





 














